#!/usr/bin/env python3

# OpenBACH is a generic testbed able to control/configure multiple
# network/physical entities (under test) and collect data from them. It is
# composed of an Auditorium (HMIs), a Controller, a Collector and multiple
# Agents (one for each network entity that wants to be tested).
#
#
# Copyright © 2016-2023 CNES
#
#
# This file is part of the OpenBACH testbed.
#
#
# OpenBACH is a free software : you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY, without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more
# details.
#
# You should have received a copy of the GNU General Public License along with
# this program. If not, see http://www.gnu.org/licenses/.


"""Provide time period summary of data generated by OpenBACH jobs"""


__author__ = 'Viveris Technologies'
__credits__ = '''Contributors:
 * Aichatou Garba Abdou <aichatou.garba-abdou@viveris.fr>
'''


import os
import syslog
import argparse
import tempfile
import itertools
from datetime import datetime

import numpy as np
import pandas as pd
from dateutil.parser import parse
from openpyxl import Workbook, load_workbook
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment, Side, Border, Font, PatternFill

import collect_agent
from data_access.post_processing import Statistics


UNIT_OPTION={'s', 'ms' ,'bits/s', 'Kbits/s', 'Mbits/s','Gbits/s','Bytes' ,'KBytes', 'MBytes', 'GBytes'}


def worksheet_style(worksheet, title):
    worksheet.title = title
    fill_color = PatternFill(fill_type='solid',start_color='00333399',end_color='FF000000')
    border_color = Side(border_style='thin', color='000000')

    for index, column in enumerate(worksheet.columns, 1):
        column_letter = get_column_letter(index)
        worksheet['{}1'.format(column_letter)].fill = fill_color
        worksheet['{}1'.format(column_letter)].font = Font(size=12, bold=True, color='00FFFFFF')
        for cell in column:
            cell.border = Border(top=border_color, bottom=border_color, left=border_color, right=border_color)
            cell.alignment = Alignment(horizontal='center', vertical='center')
        worksheet.column_dimensions[column_letter].width = 20

    for index, _ in enumerate(worksheet.rows, 1):
        A = get_column_letter(1)
        worksheet.row_dimensions[index].height = 30
        worksheet['{}{}'.format(A, index)].fill = fill_color
        worksheet['{}{}'.format(A, index)].font = Font(size=12, bold=True, color='00FFFFFF')


def _get_column_letter(worksheet, value):
    for index, column in enumerate(worksheet.columns, 1):
        for cell in column:
            if cell.value == value:
                return get_column_letter(index)
            # Only check first cell (header) of each column
            break


def get_evol_value(filepath, field, stats):
    if filepath:
        workbook = load_workbook(filepath)
        worksheet = workbook[field]
        def extract_values(column):
            it = iter(worksheet[column])
            next(it)  # Skip header
            return [cell.value for cell in it]

        column = _get_column_letter(worksheet, stats)
        if column is not None:
            values = extract_values(column)
            index = extract_values(get_column_letter(1))
            return pd.Series(values, index=index, name=stats)

    return pd.Series([], name=stats, dtype=float)


def reference_style(worksheet, percentage, column_title):
    column = _get_column_letter(worksheet, column_title)
    if column is None:
        return

    row = len(worksheet[column])  # Get last row index
    if percentage <= 33:
        font_color = "ff0000"
    elif percentage <= 66:
        font_color = "ff7f00"
    else:
        font_color = "00ff00"

    worksheet[f'{column}{row}'].font = Font(color=font_color)


def get_trend(stability_threshold, value, reference):
    threshold = reference * stability_threshold / 100
    difference = value - reference
    if np.isnan(difference):
        return 'NaN'

    if difference < -threshold:
        state = '\u2198'  # Down arrow
    elif difference <= threshold:
        state = '\u268C'  # Equal sign
    else:
        state = '\u2197'  # Up arrow

    return f'{state} {difference * 100 / reference}%'


def multiplier(base, unit):
        if unit == base:
                return 1
        if unit.startswith('GBytes'):
                return 1024 * 1024 * 1024
        if unit.startswith('MBytes'):
                return 1024 * 1024
        if unit.startswith('KBytes'):
                return 1024
        if unit.startswith('m'):
                return 0.001
        if unit.startswith('s'):
                return 1000
        if unit.startswith('Gbits'):
                return 1000 * 1000 * 1000
        if unit.startswith('Mbits'):
                return 1000 * 1000
        if unit.startswith('Kbits'):
                return 1000

        return 1


def main(
        agent_name, job_name, statistic_name, timestamp_boundaries,
        start_day, start_evening, start_night,
        reference, stability_threshold, stat_unit, table_unit,
        path_to_file, stat_title, compute_median, compute_mean, stats_with_suffixes):

    statistics = Statistics.from_default_collector()
    statistics.origin = 0
    with tempfile.TemporaryDirectory(prefix='openbach-summary_time_period-') as root_folder:
        if not timestamp_boundaries:
            timestamp = None
        else:
            begin_date, end_date = map(parse, timestamp_boundaries)
            timestamp = [int(begin_date.timestamp() * 1000), int(end_date.timestamp() * 1000)]

        data_collection = statistics.fetch_all(
                job=job_name, agent=agent_name,
                suffix = None if stats_with_suffixes else '',
                fields=[statistic_name],timestamps=timestamp)

        workbook = Workbook()
        worksheet = workbook.active

        scale_factor = 1 if stat_unit is None else multiplier(stat_unit, table_unit or stat_unit)
        means = data_collection.compute_function('mean', scale_factor, start_day, start_evening, start_night).round(2)
        medians = data_collection.compute_function('median', scale_factor, start_day, start_evening, start_night).round(2)
        means_ref = get_evol_value(path_to_file, statistic_name, 'Moyenne')
        medians_ref = get_evol_value(path_to_file, statistic_name, 'Médiane')
        df = pd.concat([means, means_ref, medians, medians_ref], axis=1)

        header = [f'{statistic_name} ({table_unit})' if table_unit else statistic_name]
        if compute_mean:
            header.extend(('Moyenne', '% Moyenne Cible'))
            if path_to_file:
                header.append('Évolution de la Moyenne')
        if compute_median:
            header.extend(('Médiane', '% Médiane Cible'))
            if path_to_file:
                header.append('Évolution de la Médiane')

        worksheet.append(header)

        moments = pd.Series([
            idx
            for moment in ('Jour', 'Soir', 'Nuit')
            for idx in df.index
            if isinstance(idx, str) and idx.startswith(moment)
        ])
        for moment, (mean, mean_ref, median, median_ref) in df.loc[moments].iterrows():
            row = [moment]
            if compute_mean:
                mean_percent = mean * 100 / reference
                row.extend((mean, f'{mean_percent}%'))
                if path_to_file:
                    row.append(get_trend(stability_threshold, mean, mean_ref))
            if compute_median:
                median_percent = median * 100 / reference
                row.extend((median, f'{median_percent}%'))
                if path_to_file:
                    row.append(get_trend(stability_threshold, median, median_ref))

            worksheet.append(row)

            if compute_mean:
                reference_style(worksheet, mean_percent, '% Moyenne Cible')
            if compute_median:
                reference_style(worksheet, median_percent, '% Médiane Cible')

        worksheet_style(worksheet, stat_title or statistic_name)
        filepath = os.path.join(root_folder, 'summary_time_period_{}.xlsx'.format(statistic_name))
        workbook.save(filepath)
        collect_agent.store_files(collect_agent.now(), figure=filepath)


if __name__ == '__main__':
    with collect_agent.use_configuration('/opt/openbach/agent/jobs/summary_time_period/summary_time_period_rstats_filter.conf'):
        parser = argparse.ArgumentParser(description=__doc__)
        parser.add_argument(
                'agent', metavar='AGENT_NAME',
                help='Agent name to fetch data from')
        parser.add_argument(
                'job', metavar='JOB_NAME',
                help='Job name to fetch data from')
        parser.add_argument(
                'statistic', metavar='STATISTIC',
                help='Statistic name to be analysed')
        parser.add_argument(
                'reference', metavar='REFERENCE', type=int,
                help='Reference value for comparison in desired stat unit')
        parser.add_argument(
                '-d', '--timestamp-boundaries',
                metavar=('BEGIN_DATE', 'END_DATE'), nargs=2,
                help='Start and End date in format YYYY:MM:DD hh:mm:ss')
        parser.add_argument(
                '-D', '--start-day',
                metavar='START_DAY', type=int, default=7,
                help='Starting time of the day')
        parser.add_argument(
                '-E', '--start-evening',
                metavar='START_EVENING', type=int, default=18,
                help='Starting time of the evening')
        parser.add_argument(
                '-N', '--start-night',
                metavar='START_NIGHT', type=int, default=0,
                help='starting time of the night')
        parser.add_argument(
                '-l', '--stability-threshold', '--threshold',
                metavar='THRESHOLD', type=int, default=10,
                help='Percentage level under which the evolution is considered stable')
        parser.add_argument(
                '-p', '--path-to-file', metavar='PATH',
                help='Path to XLSX file for evolution calculation')
        parser.add_argument(
                '-u', '--stat-unit',
                metavar='STAT_UNIT', choices=UNIT_OPTION,
                help='Unit of the statistic')
        parser.add_argument(
                '-U', '--table-unit',
                metavar='TABLE_UNIT', choices=UNIT_OPTION,
                help='Unit to show on the table')
        parser.add_argument(
                '-t', '--stat-title',
                help='Statistic name to display on the table')
        parser.add_argument(
                '-w', '--no-suffix', action='store_true',
                help='Do not show statistics with suffixes')
        parser.add_argument(
                '--no_median', action='store_true',
                help='Do not compute median')
        parser.add_argument(
                '--no_mean', action='store_true',
                help='Do not compute mean')

        args = parser.parse_args()
        compute_median = not args.no_median
        compute_mean = not args.no_mean
        stats_with_suffixes = not args.no_suffix

        main(
            args.agent, args.job, args.statistic, args.timestamp_boundaries,
            args.start_day, args.start_evening, args.start_night, args.reference,
            args.stability_threshold, args.stat_unit, args.table_unit,
            args.path_to_file, args.stat_title, compute_median, compute_mean, stats_with_suffixes)
